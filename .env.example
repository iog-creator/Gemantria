# Deterministic seeds + endpoints for real-inference runs
GEMANTRIA_SEED=20251024
PYTHONHASHSEED=20251024
API_HOST=localhost
API_PORT=8000
LM_CHAT_HOST=localhost
LM_CHAT_PORT=9991
LM_EMBED_HOST=localhost
LM_EMBED_PORT=9994

# --- Database (Phase-1) ---
# Read-only upstream scripture DB (app-layer enforces RO)
BIBLE_DSN=postgres://bible_ro:password@localhost:5432/bible_db
# Read-write target for gematria schema
GEMATRIA_DSN=postgres://gematria_rw:password@localhost:5432/gemantria

# --- Inference Providers ---
# Provider selection: vllm | lmstudio
INFERENCE_PROVIDER=vllm

# vLLM configuration (for theology model)
VLLM_BASE_URL=http://127.0.0.1:8001/v1
# Theology model (HF id when using vLLM, or LM Studio name for gguf route)
# vLLM route:
THEOLOGY_MODEL=sleepdeprived3/Reformed-Christian-Bible-Expert-12B
# LM Studio route (legacy):
# THEOLOGY_MODEL=christian-bible-expert-v2.0-12b

# LM Studio configuration (legacy GGUF)
OPENAI_BASE_URL=http://127.0.0.1:1234/v1

# Embeddings and reranker (HF models)
EMBEDDING_MODEL=BAAI/bge-m3
EMBED_BATCH=512
RERANKER_MODEL=Qwen/Qwen3-Reranker-8B
RERANK_BATCH=128

# Math model (LM Studio)
MATH_MODEL=self-certainty-qwen3-1.7b-base-math
