# Gemantria System ‚Äî Comprehensive Implementation Report
## Phase-7 Governance Reconstruction Context

> **Generated**: 2025-11-16  
> **Branch**: feat/phase7.governance.rebuild.20251116-085215  
> **Purpose**: Single authoritative document for GPT to understand what exists and complete Phase-7 governance reconstruction
> **Scope**: Full system audit showing existing infrastructure vs what needs to be done

---

# EXECUTIVE SUMMARY

The Gemantria system is a **mature, production-ready gematria analysis pipeline** with:

- ‚úÖ **Core Pipeline (Phases 0-5)**: 100% complete and operational
- ‚úÖ **Phase-7F/7G**: Local LM architecture, status introspection, UI/TVs complete  
- ‚ö†Ô∏è **Phase-6**: 60% complete (knowledge/LM wiring partial)
- üöß **Phase-7 Governance**: Infrastructure exists, needs DB-backed SSOT migration

**CRITICAL INSIGHT FOR GPT**: 

**What you're asking for ALREADY EXISTS** ‚Äî the Phase-7 governance reconstruction is about **integrating existing pieces**, not building from scratch.

**Gap**: Rules live only in `.cursor/rules/*.mdc` (69 files). Need to:
1. Add 3 DB tables to store rule definitions
2. Write 1 ingestion script to populate those tables
3. Write 1 guard script to validate sync
4. Run once + verify

**Estimated Effort**: 1 PR, 4-6 hours of focused work

---

# 1. EXISTING INFRASTRUCTURE (WHAT'S ALREADY BUILT)

## 1.1 Control-Plane Schema (Migration 040 ‚Äî COMPLETE ‚úÖ)

**Location**: `migrations/040_control_plane_schema.sql`

**Tables Implemented**:
- `control.tool_catalog` ‚Äî Tool registry with rings, IO schemas, enable flags
- `control.capability_rule` ‚Äî Capability rules with allowlist/denylist/budgets  
- `control.doc_fragment` ‚Äî Document fragments for proof-of-rewrite (PoR)
- `control.capability_session` ‚Äî Capability sessions with task_id tracking
- `control.agent_run` ‚Äî Agent runs with violations, evidence URIs, quarantine flags

**Materialized Views** (Compliance):
- `control.mv_compliance_7d` ‚Äî 7-day compliance window
- `control.mv_compliance_30d` ‚Äî 30-day compliance window
- Functions: `control.refresh_compliance(window TEXT)`

**Verification**:
```bash
pmagent control tables  # Shows all control-plane tables
pmagent control schema  # Shows DDL for control-plane
```

**Status**: ‚úÖ **COMPLETE** ‚Äî Schema is deployed and operational (verified via `pmagent control` commands)

---

## 1.2 AI Tracking Tables (Migrations 015 & 016 ‚Äî COMPLETE ‚úÖ)

**Location**: 
- `migrations/015_create_governance_tracking.sql`
- `migrations/016_create_ai_learning_tracking.sql`

**Tables Implemented**:
- `public.ai_interactions` ‚Äî AI-user interactions, tool usage, context tracking
- `public.governance_artifacts` ‚Äî Artifact tracking (rules, agents, hints, metadata)
- `public.hint_emissions` ‚Äî Hint emissions during runtime  
- `public.governance_compliance_log` ‚Äî Compliance check history
- `public.tool_usage_analytics` ‚Äî Tool performance and effectiveness
- `public.code_generation_events` ‚Äî Code generation outcomes
- `public.user_feedback` ‚Äî User satisfaction tracking

**Functions Implemented**:
- `update_governance_artifact()` ‚Äî Upsert governance artifacts
- `log_hint_emission()` ‚Äî Log hint emissions
- `check_governance_freshness()` ‚Äî Check if governance is stale

**3-Role DB Contract** (OPS v6.2.3):
- **Extraction DB**: `GEMATRIA_DSN` ‚Üí database `gematria`  
- **SSOT DB**: `BIBLE_DB_DSN` ‚Üí database `bible_db` (read-only)  
- **AI Tracking**: Lives in `gematria` DB, `public` schema; `AI_AUTOMATION_DSN` **must equal** `GEMATRIA_DSN`

**Guards**:
- `guard.ai.tracking` ‚Äî Validates tables in `public.ai_interactions`, `public.governance_artifacts`
- `guard.rules.alwaysapply.dbmirror` ‚Äî Validates Always-Apply Triad (Rules 050/051/052)

**Status**: ‚úÖ **COMPLETE** ‚Äî Schema is deployed and operational

---

## 1.3 MCP Knowledge Catalog (RFC-078, Migration 078 ‚Äî COMPLETE ‚úÖ)

**Location**: 
- `db/sql/078_mcp_knowledge.sql`
- `migrations/041_control_mcp_catalog_view.sql`

**Schema Implemented**:
- `mcp.tools` ‚Äî Tool catalog with desc, tags, cost_est, visibility
- `mcp.endpoints` ‚Äî HTTP/tool endpoints (path, method, auth, notes)
- `mcp.logs` ‚Äî Optional logs (RW in dev; OMIT in STRICT RO lanes)
- `mcp.v_catalog` ‚Äî Read-only view (tag-proof friendly)

**Guards**: 
- `guard_mcp_catalog_strict.py` ‚Äî Validates schema, counts, "no write verbs" invariant
- `guard.mcp.db.ro` ‚Äî STRICT RO proof for tags (requires `STRICT_DB_PROBE=1`)

**Exports**:
- `share/atlas/control_plane/mcp_catalog.json`
- `share/atlas/control_plane/capability_rules.json`
- `share/atlas/control_plane/agent_runs_7d.json`

**Makefile Targets**:
```bash
make mcp.catalog.export       # Export MCP catalog
make mcp.catalog.validate     # Validate MCP catalog structure
make guard.mcp.catalog.strict # Validate catalog (STRICT mode)
```

**Status**: ‚úÖ **COMPLETE** ‚Äî Schema is deployed, exports working, guards operational

---

## 1.4 Compliance Exports (Phase-3C ‚Äî COMPLETE ‚úÖ)

**Location**: 
- `agentpm/control_plane/exports.py`
- `scripts/db/control_compliance_exports.py`

**Exports Implemented**:
- `share/atlas/control_plane/compliance.head.json` ‚Äî Overall compliance summary
- `share/atlas/control_plane/top_violations_7d.json` ‚Äî Top violations (7-day window)
- `share/atlas/control_plane/top_violations_30d.json` ‚Äî Top violations (30-day window)

**Guards**:
- `guard_control_compliance_exports.py` ‚Äî Validates export structure and presence

**Functions**:
- `export_compliance_head()` ‚Äî Export HEAD summary from both windows
- `export_top_violations(window)` ‚Äî Export top violations for 7d/30d
- `write_compliance_exports(output_dir, strict_mode)` ‚Äî Write all exports with HINT/STRICT posture

**Hermetic Behavior** (Rule-046):
- All exports tolerate `db_off` mode
- Return structured JSON with `ok`, `mode`, `reason` fields
- No crashes when DB unavailable

**Makefile Targets**:
```bash
make atlas.control.exports    # Export compliance data
make guard.control.compliance # Validate compliance exports
```

**Status**: ‚úÖ **COMPLETE** ‚Äî Exports working, hermetic fallbacks implemented

---

## 1.5 PMAgent Control Commands (Phase-3B ‚Äî COMPLETE ‚úÖ)

**Location**: `pmagent/cli.py`, `scripts/control/*.py`

**Commands Implemented**:
- `pmagent control status` ‚Äî DB status + table row counts
- `pmagent control tables` ‚Äî Schema-qualified table list with row counts
- `pmagent control schema` ‚Äî DDL introspection for control-plane tables
- `pmagent control pipeline-status` ‚Äî Recent pipeline runs summary
- `pmagent control summary` ‚Äî Aggregated control-plane posture

**Hermetic Behavior** (Rule-046):
- All commands tolerate `db_off` mode (driver missing / connection failed)
- Return structured JSON with `ok`, `mode`, `reason` fields
- No crashes when DB unavailable

**Example Outputs**:
```json
{
  "ok": false,
  "mode": "db_off",
  "reason": "connection_failed: could not connect to server",
  "tables": []
}
```

**Runbooks**:
- `docs/runbooks/CONTROL_STATUS.md` ‚Äî Command usage guide
- `docs/runbooks/CONTROL_SCHEMA.md` ‚Äî Schema introspection guide
- `docs/runbooks/CONTROL_TABLES.md` ‚Äî Table inventory guide
- `docs/runbooks/CONTROL_PIPELINE_STATUS.md` ‚Äî Pipeline status guide

**Status**: ‚úÖ **COMPLETE** ‚Äî All commands implemented and tested

---

## 1.6 DSN Centralization (SSOT ‚Äî COMPLETE ‚úÖ)

**Location**: `scripts/config/env.py` (canonical SSOT)

**Loaders Implemented**:
```python
# RW DSN (write-enabled)
def get_rw_dsn():
    # GEMATRIA_DSN ‚Üí RW_DSN ‚Üí AI_AUTOMATION_DSN ‚Üí ATLAS_DSN_RW ‚Üí ATLAS_DSN
    pass

# RO DSN (read-only)
def get_ro_dsn():
    # GEMATRIA_RO_DSN | ATLAS_DSN_RO (peers) ‚Üí ATLAS_DSN ‚Üí (fallback) RW
    pass

# Bible DB DSN (read-only)
def get_bible_db_dsn():
    # BIBLE_DB_DSN ‚Üí BIBLE_RO_DSN ‚Üí RO_DSN ‚Üí ATLAS_DSN_RO ‚Üí ATLAS_DSN
    pass
```

**DSN Precedence** (documented in AGENTS.md):
- **RW DSN**: `GEMATRIA_DSN` ‚Üí `RW_DSN` ‚Üí `AI_AUTOMATION_DSN` ‚Üí `ATLAS_DSN_RW` ‚Üí `ATLAS_DSN`
- **RO DSN**: `GEMATRIA_RO_DSN` | `ATLAS_DSN_RO` (peers) ‚Üí `ATLAS_DSN` ‚Üí (fallback to RW)
- **Bible DB DSN**: `BIBLE_RO_DSN` ‚Üí `RO_DSN` ‚Üí `ATLAS_DSN_RO` ‚Üí `ATLAS_DSN` (also checks `BIBLE_DB_DSN` directly)

**Contract**:
- ‚ùå **FORBIDDEN**: `os.getenv("GEMATRIA_DSN")` direct access
- ‚úÖ **REQUIRED**: Always use centralized loaders from `scripts.config.env`

**Guard**:
- `guard_dsn_centralized.sh` ‚Äî Validates no direct `os.getenv()` calls
- `make guard.dsn.centralized` ‚Äî HINT mode
- `make guard.dsn.centralized.strict` ‚Äî STRICT mode (fail-closed)

**Makefile Target**:
```bash
make dsns.echo  # Print redacted DSNs (never prints secrets)
```

**Status**: ‚úÖ **COMPLETE** ‚Äî Centralized loaders operational, contract enforced

---

## 1.7 Guards System (60+ Guards ‚Äî COMPLETE ‚úÖ)

**Location**: `scripts/guards/`

**Key Guards Implemented**:

### Governance Guards:
- `guard_ai_tracking_contract.py` ‚Äî AI tracking in gematria DB (Rule-064)
- `guard_alwaysapply_dbmirror.py` ‚Äî Always-Apply Triad DB mirror (Rules 050/051/052)
- `guard_control_compliance_exports.py` ‚Äî Compliance export structure
- `guard_control_knowledge_mcp_exports.py` ‚Äî MCP knowledge exports
- `guard_docs_consistency.py` ‚Äî Doc consistency patterns
- `guard_db_health.py` ‚Äî DB health posture (ready/db_off/partial)
- `guard_lm_health.py` ‚Äî LM Studio health posture (lm_ready/lm_off)

### Schema Guards:
- `guard_exports_json.py` ‚Äî Export JSON structure validation
- `guard_exports_rfc3339.py` ‚Äî RFC3339 timestamp validation
- `guard_schema_smoke.py` ‚Äî Schema smoke tests
- `guard_schema_contract.py` ‚Äî Schema contract enforcement

### DSN Guards:
- `guard_dsn_centralized.sh` ‚Äî DSN centralization enforcement

### Rules Guards:
- `rules_guard.py` ‚Äî Rules numbering, status, and structure validation

**Posture Modes**:
- **HINT mode**: Tolerant, warns only (default on PRs)
- **STRICT mode**: Fail-closed (tags, releases)

**Makefile Targets**:
```bash
make guards.all              # Run all guards (HINT mode)
make guards.strict           # Run all guards (STRICT mode)
make guard.dsn.centralized   # DSN centralization (HINT)
make guard.db.health         # DB health (HINT)
make guard.lm.health         # LM health (HINT)
```

**Status**: ‚úÖ **COMPLETE** ‚Äî Guard system operational, 60+ guards implemented

---

## 1.8 Phase-7F/7G Implementation (COMPLETE ‚úÖ)

**Phase-7F Features** ‚úÖ:
- Per-slot provider configuration (local_agent, embedding, reranker, theology)
- Provider routing via env vars (`INFERENCE_PROVIDER`, `*_PROVIDER`)
- Provider enable/disable flags (`OLLAMA_ENABLED`, `LM_STUDIO_ENABLED`)
- Default models:
  - `granite4:tiny-h` (local_agent)
  - `granite-embedding:278m` (embedding)
  - `bge-reranker-v2-m3:latest` (reranker)
  - `Christian-Bible-Expert-v2.0-12B` (theology)

**Phase-7G Features** ‚úÖ:
- `pmagent lm.status` command ‚Äî LM provider/model introspection
- System status UI: `/api/status/system`, `/status` page
- TVs: `TV-LM-HEALTH-01`, `TV-DB-HEALTH-01`
- Status explanation: `pmagent status.explain` + `/api/status/explain`
- LM insights: `/api/lm/indicator` + `/lm-insights` page
- System dashboard: `/dashboard`
- DB health graph: `/api/db/health_timeline` + `/db-insights`
- BibleScholar UI: `/api/bible/passage` + `/bible`

**Documentation**:
- `docs/PHASE_7F_SUMMARY.md` ‚Äî Phase-7F summary
- `docs/PHASE_7F_IMPLEMENTATION_SUMMARY.md` ‚Äî Implementation details
- `docs/PHASE_7F_MODEL_READINESS_CHECKLIST.md` ‚Äî Model readiness checklist
- `docs/runbooks/OLLAMA_ALTERNATIVE.md` ‚Äî Ollama provider setup
- `docs/runbooks/LM_STUDIO_SETUP.md` ‚Äî LM Studio setup

**Status**: ‚úÖ **COMPLETE** ‚Äî All Phase-7F/7G features implemented and tested

---

## 1.9 Share Directory Sync (Rule-030 ‚Äî COMPLETE ‚úÖ)

**Location**: `scripts/update_share.py`, `scripts/sync_share.py`

**Manifest**: `docs/SSOT/SHARE_MANIFEST.json` (40 items max, currently 32 items)

**Sync Mechanism**:
- Reads manifest for file list and destinations
- Change detection via SHA-256 content comparison
- Preview generation for large exports (>4KB ‚Üí head_json)
- Flat layout (all files in `share/`, no subdirectories)

**Makefile Target**:
```bash
make share.sync           # Sync all manifest items to share/
make share.manifest.verify # Verify manifest is within limits
make share.check          # Check share/ is clean and current
```

**Housekeeping Integration** (Rule-058):
- `make housekeeping` runs `share.sync` first
- All doc/governance changes trigger automatic sync

**Manifest Items** (excerpt):
- `AGENTS.md` ‚Üí `share/AGENTS.md`
- `CHANGELOG.md` ‚Üí `share/CHANGELOG.md`
- `Makefile` ‚Üí `share/Makefile`
- `docs/SSOT/MASTER_PLAN.md` ‚Üí `share/MASTER_PLAN.md`
- `docs/SSOT/GPT_REFERENCE_GUIDE.md` ‚Üí `share/GPT_REFERENCE_GUIDE.md`
- `docs/runbooks/LM_STUDIO_SETUP.md` ‚Üí `share/LM_STUDIO_SETUP.md`
- `docs/runbooks/DB_HEALTH.md` ‚Üí `share/DB_HEALTH.md`
- `env_example.txt` ‚Üí `share/env_example.txt`

**Status**: ‚úÖ **COMPLETE** ‚Äî Share sync operational, DB tracking optional

---

## 1.10 Housekeeping System (Rule-058 ‚Äî COMPLETE ‚úÖ)

**Location**: `Makefile` (target: `housekeeping`)

**Components**:
```makefile
housekeeping: share.sync adr.housekeeping governance.housekeeping \
              governance.docs.hints docs.hints docs.masterref.populate \
              handoff.update
    # 1. Share sync (Rule-030)
    # 2. ADR housekeeping (format validation)
    # 3. Governance housekeeping (DB + compliance + docs)
    # 4. Governance docs hints (Rule-026 + Rule-065)
    # 5. Document hints (Rule-050 + Rule-061)
    # 6. Master reference population
    # 7. Handoff update
    # 8. Create missing AGENTS.md files (Rule-017, Rule-058)
    # 9. Auto-update AGENTS.md based on code changes
    # 10. Auto-update CHANGELOG.md based on commits
    # 11. Validate AGENTS.md
    # 12. Rules audit
    # 13. Forest generation
    # 14. PM snapshot generation
```

**Scripts**:
- `scripts/sync_share.py` ‚Äî Share directory sync
- `scripts/governance_housekeeping.py` ‚Äî Governance updates
- `scripts/governance_docs_hints.py` ‚Äî Hint emission for doc changes
- `scripts/create_agents_md.py` ‚Äî Create missing AGENTS.md files
- `scripts/auto_update_agents_md.py` ‚Äî Auto-update AGENTS.md
- `scripts/auto_update_changelog.py` ‚Äî Auto-update CHANGELOG.md
- `scripts/validate_agents_md.py` ‚Äî Validate AGENTS.md structure
- `scripts/rules_audit.py` ‚Äî Rules numbering/status validation
- `scripts/generate_forest.py` ‚Äî Generate forest overview
- `scripts/pm_snapshot.py` ‚Äî Generate PM snapshot

**Mandatory Run** (Rule-058):
- After ANY docs/scripts/rules changes
- Before requesting review
- Failure to run = CI failure

**Status**: ‚úÖ **COMPLETE** ‚Äî Full housekeeping pipeline operational

---

## 1.11 Cursor Rules System (69 Rules ‚Äî COMPLETE ‚úÖ)

**Location**: `.cursor/rules/` (69 .mdc files + README)

**Rules Structure**:
- **000-068**: Contiguous numbering (no gaps except reserved 047/048)
- **Always-Apply Triad**: Rule-050 (OPS), Rule-051 (CI gating), Rule-052 (tool priority)
- **Status types**: `active`, `deprecated`, `reserved`

**Key Rules**:
- `000-ssot-index.mdc` ‚Äî SSOT index (deprecated)
- `050-ops-contract.mdc` ‚Äî OPS contract v6.2.3 (Always-Apply)
- `051-cursor-insight.mdc` ‚Äî CI gating and handoff (Always-Apply)
- `052-tool-priority.mdc` ‚Äî Tool priority and context (Always-Apply)
- `058-auto-housekeeping.mdc` ‚Äî Mandatory housekeeping (Always-Apply)
- `062-environment-validation.mdc` ‚Äî Venv validation (Always-Apply)
- `063-git-safety.mdc` ‚Äî Git safety (Always-Apply)

**Rules Inventory** (in AGENTS.md):
```markdown
| # | Title |
|---:|-------|
| 000 | # 000-ssot-index (AlwaysApply) |
| 001 | # --- (db-safety) |
...
| 068 | # --- (gpt-docs-sync) |
```

**Validation**:
- `scripts/rules_audit.py` ‚Äî Validates numbering, status, structure
- `make rules.audit` ‚Äî Run rules audit

**Status**: ‚úÖ **COMPLETE** ‚Äî 69 rules implemented, contiguous numbering verified

---

## 1.12 AGENTS.md Governance (Rule-006 ‚Äî COMPLETE ‚úÖ)

**Root AGENTS.md**: Canonical agent framework documentation

**Scoped AGENTS.md Files**:
- `scripts/AGENTS.md` ‚Äî Scripts directory documentation
- `agentpm/AGENTS.md` ‚Äî AgentPM package documentation
- `src/AGENTS.md` ‚Äî Source code documentation
- (Others created as needed via `scripts/create_agents_md.py`)

**Content Requirements** (Rule-006):
- Directory purpose statement
- API contracts and function signatures
- Behavior documentation for key functions/classes
- Integration points and dependencies

**Auto-Generation**:
- `scripts/create_agents_md.py` ‚Äî Create missing AGENTS.md files
- `scripts/auto_update_agents_md.py` ‚Äî Auto-update based on code changes
- `scripts/validate_agents_md.py` ‚Äî Validate structure and completeness

**Makefile Targets**:
```bash
make agents.md.sync       # Check for stale AGENTS.md files
make agents.md.validate   # Validate AGENTS.md structure
```

**Housekeeping Integration**:
- `make housekeeping` automatically creates missing AGENTS.md files
- Validation runs as part of housekeeping

**Status**: ‚úÖ **COMPLETE** ‚Äî AGENTS.md governance operational

---

# 2. WHAT'S MISSING (GOVERNANCE SSOT MIGRATION)

## 2.1 Problem Statement

**Current State**:
- ‚úÖ Postgres control-plane schema exists
- ‚úÖ AI tracking tables exist
- ‚úÖ MCP catalog exists
- ‚úÖ Compliance exports exist
- ‚úÖ Guards exist
- ‚ùå **Rules definitions NOT in DB** ‚Äî live only in `.cursor/rules/*.mdc`
- ‚ùå **No DB-driven governance** ‚Äî `.cursor/rules` is de facto SSOT

**Target State**:
- ‚úÖ Postgres becomes SSOT for governance
- ‚úÖ Rules defined in DB (`control.rule_definition`)
- ‚úÖ `.cursor/rules/*.mdc` generated FROM DB (or sync validated)
- ‚úÖ Guards validate DB SSOT
- ‚úÖ CI lanes enforce SSOT consistency

**Gap Analysis**:

| Component | Exists? | Status |
|-----------|---------|--------|
| Control-plane schema | ‚úÖ | Complete |
| AI tracking tables | ‚úÖ | Complete |
| MCP catalog | ‚úÖ | Complete |
| Compliance exports | ‚úÖ | Complete |
| Rules in `.cursor/rules/` | ‚úÖ | Complete (69 files) |
| **Rules in DB** | ‚ùå | **Missing** |
| **Ingestion script** | ‚ùå | **Missing** |
| **DB SSOT guard** | ‚ùå | **Missing** |

---

## 2.2 What Needs to Be Built (Minimal Scope)

### 2.2.1 New DB Tables (Migration 0XX)

**File**: `migrations/042_governance_rules_ssot.sql`

**Tables to Create**:

#### A. `control.rule_definition`

```sql
CREATE TABLE control.rule_definition (
    rule_id TEXT PRIMARY KEY,           -- "000", "001", ..., "068"
    name TEXT NOT NULL,                 -- "ssot-index", "db-safety", etc.
    status TEXT NOT NULL,               -- "active", "deprecated", "reserved"
    description TEXT,
    severity TEXT NOT NULL,             -- "HINT", "STRICT"
    always_apply BOOLEAN NOT NULL DEFAULT FALSE,
    docs_path TEXT,                     -- ".cursor/rules/000-ssot-index.mdc"
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

COMMENT ON TABLE control.rule_definition IS 
'Rule definitions SSOT - canonical source for governance rules';

COMMENT ON COLUMN control.rule_definition.rule_id IS 
'Rule identifier (000-068), contiguous numbering enforced';

COMMENT ON COLUMN control.rule_definition.always_apply IS 
'If true, this rule is part of the Always-Apply set (e.g., 050/051/052)';
```

#### B. `control.rule_source`

```sql
CREATE TABLE control.rule_source (
    id SERIAL PRIMARY KEY,
    rule_id TEXT NOT NULL REFERENCES control.rule_definition(rule_id),
    source_type TEXT NOT NULL,          -- "cursor_rules", "rules_index", "agents_md"
    path TEXT NOT NULL,
    content_hash TEXT NOT NULL,         -- SHA-256
    content TEXT,                       -- Full .mdc content (optional)
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_rule_source_rule_id ON control.rule_source(rule_id);
CREATE INDEX idx_rule_source_type ON control.rule_source(source_type);

COMMENT ON TABLE control.rule_source IS 
'Rule source tracking - maps DB rules to .cursor/rules/*.mdc files';
```

#### C. `control.guard_definition`

```sql
CREATE TABLE control.guard_definition (
    guard_id TEXT PRIMARY KEY,          -- "guard_db_health", etc.
    name TEXT NOT NULL,
    description TEXT,
    rule_ids TEXT[] NOT NULL,           -- Rules this guard enforces
    strict_default BOOLEAN NOT NULL DEFAULT FALSE,
    script_path TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_guard_rule_ids ON control.guard_definition USING GIN(rule_ids);

COMMENT ON TABLE control.guard_definition IS 
'Guard definitions - maps guards to rules they enforce';
```

**Migration Verification**:
```bash
psql $GEMATRIA_DSN -c "SELECT COUNT(*) FROM control.rule_definition;"
# Expected: 0 (empty until ingestion)

psql $GEMATRIA_DSN -c "SELECT COUNT(*) FROM control.rule_source;"
# Expected: 0 (empty until ingestion)
```

---

### 2.2.2 Ingestion Script

**File**: `scripts/governance/ingest_rules_to_db.py`

**Purpose**: Parse `.cursor/rules/*.mdc` and `RULES_INDEX.md` ‚Üí populate DB

**Algorithm**:

```python
#!/usr/bin/env python3
"""
ingest_rules_to_db.py ‚Äî Ingest .cursor/rules/*.mdc ‚Üí control.rule_definition
"""

import hashlib
import json
import re
from pathlib import Path
from datetime import datetime
import psycopg

from scripts.config.env import get_rw_dsn

ROOT = Path(__file__).resolve().parent.parent.parent
RULES_DIR = ROOT / ".cursor" / "rules"
RULES_INDEX = ROOT / "RULES_INDEX.md"

def parse_rule_file(path: Path) -> dict:
    """
    Parse a .cursor/rules/NNN-name.mdc file.
    Extract:
    - rule_id (from filename)
    - name (from filename or content)
    - status (from content: "DEPRECATED", "reserved", or "active")
    - description (from first header)
    - severity (from content: "STRICT" or "HINT")
    - always_apply (from content: "AlwaysApply" or "Always-Apply")
    - content_hash (SHA-256)
    """
    content = path.read_text()
    
    # Extract rule_id from filename: "NNN-name.mdc"
    match = re.match(r"(\d{3})-(.+)\.mdc", path.name)
    if not match:
        return None
    
    rule_id = match.group(1)
    name_slug = match.group(2)
    
    # Parse content
    status = "active"
    if "DEPRECATED" in content or "deprecated" in content.lower():
        status = "deprecated"
    elif "reserved" in content.lower():
        status = "reserved"
    
    # Extract description (first header line starting with #)
    description = None
    for line in content.split("\n"):
        if line.startswith("# "):
            description = line[2:].strip()
            break
    
    # Determine severity
    severity = "HINT"
    if "STRICT" in content or "strict" in content:
        severity = "STRICT"
    
    # Determine always_apply
    always_apply = False
    if "AlwaysApply" in content or "Always-Apply" in content:
        always_apply = True
    
    # Compute content hash
    content_hash = hashlib.sha256(content.encode()).hexdigest()
    
    return {
        "rule_id": rule_id,
        "name": name_slug,
        "status": status,
        "description": description,
        "severity": severity,
        "always_apply": always_apply,
        "docs_path": str(path.relative_to(ROOT)),
        "content_hash": content_hash,
        "content": content
    }

def ingest_rules():
    """Ingest all rules from .cursor/rules/ ‚Üí DB"""
    dsn = get_rw_dsn()
    if not dsn:
        print("ERROR: No RW DSN available")
        return 1
    
    rules = []
    for mdc_file in sorted(RULES_DIR.glob("*.mdc")):
        if mdc_file.name == "README.md":
            continue
        if mdc_file.suffix == ".tmp":
            continue
        
        rule_data = parse_rule_file(mdc_file)
        if rule_data:
            rules.append(rule_data)
    
    print(f"Parsed {len(rules)} rules from .cursor/rules/")
    
    # Connect to DB and ingest
    with psycopg.connect(dsn) as conn:
        with conn.cursor() as cur:
            # Upsert into control.rule_definition
            for rule in rules:
                cur.execute(
                    """
                    INSERT INTO control.rule_definition 
                        (rule_id, name, status, description, severity, always_apply, docs_path)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (rule_id) 
                    DO UPDATE SET
                        name = EXCLUDED.name,
                        status = EXCLUDED.status,
                        description = EXCLUDED.description,
                        severity = EXCLUDED.severity,
                        always_apply = EXCLUDED.always_apply,
                        docs_path = EXCLUDED.docs_path,
                        updated_at = NOW()
                    """,
                    (
                        rule["rule_id"],
                        rule["name"],
                        rule["status"],
                        rule["description"],
                        rule["severity"],
                        rule["always_apply"],
                        rule["docs_path"]
                    )
                )
                
                # Insert into control.rule_source
                cur.execute(
                    """
                    INSERT INTO control.rule_source
                        (rule_id, source_type, path, content_hash, content)
                    VALUES (%s, %s, %s, %s, %s)
                    ON CONFLICT DO NOTHING
                    """,
                    (
                        rule["rule_id"],
                        "cursor_rules",
                        rule["docs_path"],
                        rule["content_hash"],
                        rule["content"]
                    )
                )
            
            conn.commit()
    
    print(f"‚úÖ Ingested {len(rules)} rules into control.rule_definition")
    return 0

if __name__ == "__main__":
    exit(ingest_rules())
```

**Makefile Target**:
```makefile
.PHONY: governance.ingest.rules
governance.ingest.rules:
	@echo ">> Ingesting rules from .cursor/rules/ ‚Üí DB"
	@PYTHONPATH=. python3 scripts/governance/ingest_rules_to_db.py
	@echo "Rules ingestion complete"
```

---

### 2.2.3 Validation Guard

**File**: `scripts/guards/guard_rules_db_ssot.py`

**Purpose**: Validate that DB SSOT matches `.cursor/rules`

**Algorithm**:

```python
#!/usr/bin/env python3
"""
guard_rules_db_ssot.py ‚Äî Validate DB rules SSOT matches .cursor/rules/*.mdc
"""

import hashlib
import json
import sys
from pathlib import Path
import psycopg

from scripts.config.env import get_ro_dsn

ROOT = Path(__file__).resolve().parent.parent.parent
RULES_DIR = ROOT / ".cursor" / "rules"

def main():
    """
    Validate DB SSOT:
    1. Query control.rule_definition for all rules
    2. For each rule, check .cursor/rules/NNN-name.mdc exists
    3. Compute content_hash and compare with DB
    4. Emit HINT/FAIL based on STRICT_RULES_DB_SSOT env var
    """
    dsn = get_ro_dsn()
    if not dsn:
        print(json.dumps({
            "ok": True,
            "mode": "db_off",
            "reason": "No RO DSN available; DB unavailable (hermetic behavior)"
        }))
        return 0
    
    try:
        with psycopg.connect(dsn) as conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    SELECT rule_id, name, status, docs_path, always_apply
                    FROM control.rule_definition
                    ORDER BY rule_id
                    """
                )
                db_rules = cur.fetchall()
    except Exception as e:
        print(json.dumps({
            "ok": True,
            "mode": "db_off",
            "reason": f"DB query failed: {e}"
        }))
        return 0
    
    issues = []
    
    for rule_id, name, status, docs_path, always_apply in db_rules:
        rule_file = ROOT / docs_path if docs_path else RULES_DIR / f"{rule_id}-{name}.mdc"
        
        if not rule_file.exists():
            issues.append({
                "rule_id": rule_id,
                "issue": "file_missing",
                "expected_path": str(rule_file.relative_to(ROOT))
            })
            continue
        
        # Compute content hash
        content = rule_file.read_text()
        content_hash = hashlib.sha256(content.encode()).hexdigest()
        
        # Query DB for expected hash
        with psycopg.connect(dsn) as conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    SELECT content_hash FROM control.rule_source
                    WHERE rule_id = %s AND source_type = 'cursor_rules'
                    ORDER BY created_at DESC
                    LIMIT 1
                    """,
                    (rule_id,)
                )
                row = cur.fetchone()
                if not row:
                    issues.append({
                        "rule_id": rule_id,
                        "issue": "no_source_record",
                        "path": str(rule_file.relative_to(ROOT))
                    })
                    continue
                
                db_hash = row[0]
                if content_hash != db_hash:
                    issues.append({
                        "rule_id": rule_id,
                        "issue": "hash_mismatch",
                        "path": str(rule_file.relative_to(ROOT)),
                        "db_hash": db_hash,
                        "file_hash": content_hash
                    })
    
    # Determine posture
    strict_mode = os.getenv("STRICT_RULES_DB_SSOT") == "1"
    
    if issues:
        result = {
            "ok": not strict_mode,
            "mode": "STRICT" if strict_mode else "HINT",
            "issues": issues,
            "count": len(issues)
        }
        print(json.dumps(result, indent=2))
        return 1 if strict_mode else 0
    else:
        result = {
            "ok": True,
            "mode": "STRICT" if strict_mode else "HINT",
            "message": "All rules in sync between DB and .cursor/rules/",
            "rule_count": len(db_rules)
        }
        print(json.dumps(result, indent=2))
        return 0

if __name__ == "__main__":
    exit(main())
```

**Makefile Targets**:
```makefile
.PHONY: guard.rules.db.ssot guard.rules.db.ssot.strict
guard.rules.db.ssot:
	@mkdir -p evidence
	@python3 scripts/guards/guard_rules_db_ssot.py | tee evidence/guard_rules_db_ssot.json
	@cat evidence/guard_rules_db_ssot.json

guard.rules.db.ssot.strict:
	@mkdir -p evidence
	@STRICT_RULES_DB_SSOT=1 python3 scripts/guards/guard_rules_db_ssot.py | tee evidence/guard_rules_db_ssot.json
	@cat evidence/guard_rules_db_ssot.json
	@jq -e '.ok == true' evidence/guard_rules_db_ssot.json
```

---

### 2.2.4 Documentation

**File**: `docs/runbooks/GOVERNANCE_DB_SSOT.md`

**Content**:
```markdown
# Governance DB SSOT Runbook

## Overview

Governance rules are now stored in Postgres (`control.rule_definition`) as the single source of truth (SSOT).

## Tables

- `control.rule_definition` ‚Äî Rule metadata (id, name, status, severity, always_apply)
- `control.rule_source` ‚Äî Rule sources (path, content_hash, full content)
- `control.guard_definition` ‚Äî Guard-to-rule mappings

## Operations

### Ingest Rules to DB

```bash
make governance.ingest.rules
```

This parses `.cursor/rules/*.mdc` files and populates the DB.

### Validate DB SSOT

```bash
# HINT mode (warns only)
make guard.rules.db.ssot

# STRICT mode (fail-closed)
make guard.rules.db.ssot.strict
```

### Query Rules from DB

```sql
-- List all rules
SELECT rule_id, name, status, severity, always_apply
FROM control.rule_definition
ORDER BY rule_id;

-- Always-Apply Triad
SELECT rule_id, name FROM control.rule_definition
WHERE always_apply = true;

-- Active rules only
SELECT rule_id, name FROM control.rule_definition
WHERE status = 'active';
```

## CI Integration

- **PR CI**: Runs `guard.rules.db.ssot` (HINT mode)
- **Tag CI**: Runs `guard.rules.db.ssot.strict` (STRICT mode)

## Hermetic Behavior

- Ingestion script requires `GEMATRIA_DSN` (write-enabled)
- Guard script tolerates `db_off` mode (returns `ok: true` when DB unavailable)
```

---

## 2.3 Transition Plan

### Phase 1: Implementation (1 PR)

**Tasks**:
1. ‚úÖ Create migration `042_governance_rules_ssot.sql` with 3 tables
2. ‚úÖ Implement `scripts/governance/ingest_rules_to_db.py`
3. ‚úÖ Implement `scripts/guards/guard_rules_db_ssot.py`
4. ‚úÖ Add Makefile targets (`governance.ingest.rules`, `guard.rules.db.ssot`)
5. ‚úÖ Write runbook `docs/runbooks/GOVERNANCE_DB_SSOT.md`
6. ‚úÖ Update AGENTS.md with DB SSOT references

**Verification**:
```bash
# 1. Apply migration
psql $GEMATRIA_DSN -f migrations/042_governance_rules_ssot.sql

# 2. Run ingestion
make governance.ingest.rules

# 3. Verify DB contains rules
psql $GEMATRIA_DSN -c "SELECT COUNT(*) FROM control.rule_definition;"
# Expected: 69 (or current rule count)

# 4. Run guard
make guard.rules.db.ssot
# Expected: ok: true, no issues

# 5. Housekeeping
make housekeeping
```

---

### Phase 2: CI Integration

**Tasks**:
1. Add `guard.rules.db.ssot` to PR CI workflow (HINT mode)
2. Add `guard.rules.db.ssot.strict` to tag CI workflow (STRICT mode)
3. Update `.github/workflows/ci.yml` with new guard

**Verification**:
```yaml
# .github/workflows/ci.yml
- name: Validate Rules DB SSOT
  run: make guard.rules.db.ssot
```

---

# 3. KEY INSIGHTS FOR GPT

## 3.1 What Already Works

1. ‚úÖ **Control-Plane Schema** ‚Äî Tables exist, migrations applied
2. ‚úÖ **AI Tracking** ‚Äî Tables exist, functions work
3. ‚úÖ **MCP Catalog** ‚Äî Tables exist, exports work
4. ‚úÖ **Compliance Exports** ‚Äî JSON exports working
5. ‚úÖ **PMAgent Commands** ‚Äî All control commands implemented
6. ‚úÖ **DSN Centralization** ‚Äî Loaders operational
7. ‚úÖ **Guards System** ‚Äî 60+ guards operational
8. ‚úÖ **Phase-7F/7G** ‚Äî Local LM + UI complete
9. ‚úÖ **Share Sync** ‚Äî Manifest-driven sync working
10. ‚úÖ **Housekeeping** ‚Äî Full pipeline operational
11. ‚úÖ **Cursor Rules** ‚Äî 69 rules in `.cursor/rules/`
12. ‚úÖ **AGENTS.md Governance** ‚Äî Auto-generation working

## 3.2 What's the Gap

1. ‚ùå **No rules in DB** ‚Äî Rules live only in `.cursor/rules/*.mdc`
2. ‚ùå **No ingestion script** ‚Äî No way to populate `control.rule_definition`
3. ‚ùå **No DB SSOT guard** ‚Äî No validation of DB vs `.cursor/rules`

## 3.3 What Needs to Be Done (ONE PR)

**Scope**: Add DB-backed governance SSOT

**Files to Create**:
1. `migrations/042_governance_rules_ssot.sql` ‚Äî 3 new tables
2. `scripts/governance/ingest_rules_to_db.py` ‚Äî Ingestion script
3. `scripts/guards/guard_rules_db_ssot.py` ‚Äî Validation guard
4. `docs/runbooks/GOVERNANCE_DB_SSOT.md` ‚Äî Operations runbook

**Files to Modify**:
1. `Makefile` ‚Äî Add 3 new targets
2. `AGENTS.md` ‚Äî Add DB SSOT references

**Estimated Effort**: 1 PR, 4-6 hours of focused work

**Verification Steps**:
```bash
# 1. Apply migration
psql $GEMATRIA_DSN -f migrations/042_governance_rules_ssot.sql

# 2. Ingest rules
make governance.ingest.rules

# 3. Verify count
psql $GEMATRIA_DSN -c "SELECT COUNT(*) FROM control.rule_definition;"

# 4. Run guard
make guard.rules.db.ssot

# 5. Housekeeping
make housekeeping

# 6. PR smoke
make book.smoke && make ci.exports.smoke && make guards.all
```

---

# 4. REFERENCE FILES (Templates for GPT)

## 4.1 Existing Migrations (Templates)

- `migrations/040_control_plane_schema.sql` ‚Äî Control-plane schema template
- `migrations/015_create_governance_tracking.sql` ‚Äî Governance tracking template
- `migrations/041_control_mcp_catalog_view.sql` ‚Äî MCP catalog template

**Pattern to Follow**:
```sql
-- Migration NNN: Description
-- Author: GPT-5
-- Date: 2025-11-16

BEGIN;

-- Create schema if needed
CREATE SCHEMA IF NOT EXISTS control;

-- Create tables
CREATE TABLE control.table_name (...);

-- Create indexes
CREATE INDEX idx_name ON control.table_name(...);

-- Create comments
COMMENT ON TABLE control.table_name IS 'Description';

COMMIT;
```

---

## 4.2 Existing Guards (Templates)

- `scripts/guards/guard_ai_tracking_contract.py` ‚Äî DB contract validation template
- `scripts/guards/guard_control_compliance_exports.py` ‚Äî Export validation template
- `scripts/guards/guard_db_health.py` ‚Äî DB health check template

**Pattern to Follow**:
```python
#!/usr/bin/env python3
"""
guard_name.py ‚Äî Guard description
"""

import json
import os
import sys
import psycopg

from scripts.config.env import get_ro_dsn

def main():
    # 1. Get RO DSN (hermetic behavior)
    dsn = get_ro_dsn()
    if not dsn:
        print(json.dumps({
            "ok": True,
            "mode": "db_off",
            "reason": "No RO DSN available"
        }))
        return 0
    
    # 2. Connect and validate
    try:
        with psycopg.connect(dsn) as conn:
            # ... validation logic ...
            pass
    except Exception as e:
        # Hermetic: tolerate DB failures
        print(json.dumps({
            "ok": True,
            "mode": "db_off",
            "reason": f"DB error: {e}"
        }))
        return 0
    
    # 3. Check STRICT mode
    strict_mode = os.getenv("STRICT_GUARD_NAME") == "1"
    
    # 4. Return result
    result = {
        "ok": True,  # or False if issues found
        "mode": "STRICT" if strict_mode else "HINT",
        # ... other fields ...
    }
    print(json.dumps(result, indent=2))
    return 0 if result["ok"] else 1

if __name__ == "__main__":
    exit(main())
```

---

## 4.3 Existing Loaders (Templates)

- `scripts/config/env.py` ‚Äî DSN loaders template
- `agentpm/db/loader.py` ‚Äî SQLAlchemy engines template

**DSN Loader Pattern**:
```python
from scripts.config.env import get_rw_dsn, get_ro_dsn

# Write-enabled DSN
rw_dsn = get_rw_dsn()

# Read-only DSN
ro_dsn = get_ro_dsn()
```

---

## 4.4 Existing Runbooks (Templates)

- `docs/runbooks/CONTROL_STATUS.md` ‚Äî Command usage template
- `docs/runbooks/MCP_KNOWLEDGE_DB.md` ‚Äî DB usage template
- `docs/runbooks/DB_HEALTH.md` ‚Äî Health check template

**Runbook Pattern**:
```markdown
# Feature Name Runbook

## Overview

Brief description of feature.

## Commands

### Command 1

```bash
make target.name
```

Description of what this does.

## Verification

Steps to verify the feature works.

## Troubleshooting

Common issues and solutions.
```

---

# 5. CONCLUSION

The Gemantria system has **all the infrastructure needed** for Phase-7 governance reconstruction. The missing piece is **populating the DB with rules** and **validating the sync**.

**GPT does NOT need to**:
- ‚ùå Build control-plane schema (exists)
- ‚ùå Build AI tracking tables (exists)
- ‚ùå Build PMAgent commands (exists)
- ‚ùå Build guards system (exists)
- ‚ùå Build share sync (exists)
- ‚ùå Build housekeeping (exists)

**GPT ONLY needs to**:
- ‚úÖ Add 3 new tables for rule definitions (migration 042)
- ‚úÖ Write ingestion script (parse `.cursor/rules/*.mdc` ‚Üí DB)
- ‚úÖ Write guard script (validate DB matches `.cursor/rules`)
- ‚úÖ Add 3 Makefile targets
- ‚úÖ Write 1 runbook
- ‚úÖ Update AGENTS.md
- ‚úÖ Run once + verify
- ‚úÖ Open PR

**This is integration work, not greenfield development.**

---

# 6. APPENDIX: File Inventory

## Control-Plane Files (Existing)

```
migrations/040_control_plane_schema.sql          ‚úÖ
migrations/015_create_governance_tracking.sql    ‚úÖ
migrations/016_create_ai_learning_tracking.sql   ‚úÖ
migrations/041_control_mcp_catalog_view.sql      ‚úÖ

scripts/config/env.py                            ‚úÖ
agentpm/db/loader.py                            ‚úÖ

agentpm/control_plane/exports.py                 ‚úÖ
scripts/db/control_compliance_exports.py         ‚úÖ
scripts/db/control_lm_metrics_export.py          ‚úÖ

scripts/guards/guard_ai_tracking_contract.py     ‚úÖ
scripts/guards/guard_alwaysapply_dbmirror.py     ‚úÖ
scripts/guards/guard_control_compliance_exports.py ‚úÖ
scripts/guards/guard_db_health.py                ‚úÖ
scripts/guards/guard_lm_health.py                ‚úÖ

pmagent/cli.py                                   ‚úÖ
scripts/control/*.py                             ‚úÖ

docs/runbooks/CONTROL_STATUS.md                  ‚úÖ
docs/runbooks/CONTROL_SCHEMA.md                  ‚úÖ
docs/runbooks/CONTROL_TABLES.md                  ‚úÖ
docs/runbooks/MCP_KNOWLEDGE_DB.md                ‚úÖ
```

## Governance Files (To Create)

```
migrations/042_governance_rules_ssot.sql         ‚ùå (needs creation)
scripts/governance/ingest_rules_to_db.py         ‚ùå (needs creation)
scripts/guards/guard_rules_db_ssot.py            ‚ùå (needs creation)
docs/runbooks/GOVERNANCE_DB_SSOT.md              ‚ùå (needs creation)
```

## Governance Files (Existing)

```
.cursor/rules/000-ssot-index.mdc                 ‚úÖ (69 total)
AGENTS.md                                        ‚úÖ
RULES_INDEX.md                                   ‚úÖ

scripts/update_share.py                          ‚úÖ
scripts/sync_share.py                            ‚úÖ
scripts/governance_housekeeping.py               ‚úÖ
scripts/governance_docs_hints.py                 ‚úÖ
scripts/rules_audit.py                           ‚úÖ
scripts/create_agents_md.py                      ‚úÖ
scripts/auto_update_agents_md.py                 ‚úÖ
scripts/validate_agents_md.py                    ‚úÖ
scripts/generate_forest.py                       ‚úÖ
scripts/pm_snapshot.py                           ‚úÖ

docs/SSOT/SHARE_MANIFEST.json                    ‚úÖ
docs/SSOT/MASTER_PLAN.md                         ‚úÖ
docs/SSOT/GPT_REFERENCE_GUIDE.md                 ‚úÖ
```

---

**END OF COMPREHENSIVE SYSTEM REPORT**

---

**Usage Instructions for GPT**:

1. Read this entire report carefully
2. Understand that 95% of what you need already exists
3. Focus ONLY on the 4 files to create (section 2.2)
4. Use existing templates from section 4 as patterns
5. Verify using commands in section 2.3
6. Open ONE PR with all changes

**DO NOT**:
- Rebuild existing infrastructure
- Create new guard patterns (use templates)
- Invent new DSN loaders (use `scripts.config.env`)
- Create new migration patterns (follow existing ones)

**DO**:
- Follow existing patterns exactly
- Test locally before opening PR
- Run `make housekeeping` after all changes
- Include verification steps in PR description

